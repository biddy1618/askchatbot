{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA and ETL for scraped data from IPM and AskExtension data knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "COLOR = 'white'\n",
    "plt.rcParams['text.color'       ] = COLOR\n",
    "plt.rcParams['text.color'       ] = COLOR\n",
    "plt.rcParams['axes.labelcolor'  ] = COLOR\n",
    "plt.rcParams['xtick.color'      ] = COLOR\n",
    "plt.rcParams['ytick.color'      ] = COLOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPM data - December 2021 Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "['exoticPests.json',\n",
    " 'fruitItems_new.json',\n",
    " 'fruitVeggieEnvironItems_new.json',\n",
    " 'pestDiseaseItems_new.json',\n",
    " 'plantFlowerItems.json',\n",
    " 'turfPests.json',\n",
    " 'veggieItems_new.json',\n",
    " 'weedItems.json']\n",
    "'''\n",
    "_PATH = '../data/uc-ipm/updated-Dec2021/'\n",
    "DATA_FILE_NAMES = sorted(os.listdir(_PATH))\n",
    "DATA_FILE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDf = pd.DataFrame()\n",
    "cols = ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']\n",
    "\n",
    "\n",
    "def pestsDiseases():\n",
    "    # -------------------------------------------- Pests diseases\n",
    "    print(f'Merging pests diseases...')\n",
    "    FILE_NAME = 'pestDiseaseItems_new.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description identification life_cycle damage solutions images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'] = 'pestsDiseases'\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'          : 'title'       ,\n",
    "        'life_cycle'    : 'development' ,\n",
    "        'damagePestNote': 'damage'      ,\n",
    "        'solutions'     : 'management'  ,\n",
    "        'images'        : 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = pestsDiseases()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def pestsTurf():\n",
    "    # -------------------------------------------- Turf pests\n",
    "    print(f'Merging turf pests...')\n",
    "    FILE_NAME = 'turfPests.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url text images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'pestsTurf'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title'       ,\n",
    "        'text'  : 'description' ,\n",
    "        'images': 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = pestsTurf()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def pestsExotic():\n",
    "    # -------------------------------------------- Exotic pests\n",
    "    print(f'Merging exotic pests...')\n",
    "    FILE_NAME = 'exoticPests.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description damage identification life_cycle monitoring management related_links images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'] = 'pestsExotic'\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'      : 'title'       ,\n",
    "        'life_cycle': 'development' ,\n",
    "        'images'    : 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df['links'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "    \n",
    "    df['related_links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'page'   , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['text']\n",
    "        } for i in r['related_links'] if len(i['text']) > 0], axis = 1)\n",
    "\n",
    "    df.apply(lambda x: x['links'].extend(x['related_links' ]), axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = pestsExotic()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def damagesEnvironment():\n",
    "    # -------------------------------------------- Fruit and veggie damages\n",
    "    print(f'Merging fruit and veggie damages...')\n",
    "    FILE_NAME = 'fruitVeggieEnvironItems_new.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description identification damage disorder_development solutions images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'] = 'damagesEnvironment'\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'                  : 'title'       ,\n",
    "        'disorder_development'  : 'development' ,\n",
    "        'solutions'             : 'management' ,\n",
    "        'images'                : 'links'      ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = damagesEnvironment()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def damagesWeed():\n",
    "    # -------------------------------------------- Weed damages\n",
    "    print(f'Merging weed damages...')\n",
    "    FILE_NAME = 'weedItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'damagesWeed'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title',\n",
    "        'images': 'links'\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = damagesWeed()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def infoFruits():\n",
    "    # -------------------------------------------- Fruits information\n",
    "    print(f'Merging fruits information...')\n",
    "    FILE_NAME = 'fruitItems_new.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url cultural_tips pests_and_disorders\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoFruits'\n",
    "    df['description'    ] = ''\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "    \n",
    "    df.rename(columns = {\n",
    "        'name'          : 'title',\n",
    "        'cultural_tips' : 'links'\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df['links'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'tip'     , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['tip']\n",
    "        } for i in r['links'] if len(i['tip']) > 0], axis = 1)\n",
    "\n",
    "    df['pests_and_disorders'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'problem' , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['problem']\n",
    "        } for i in r['pests_and_disorders'] if len(i['problem']) > 0], axis = 1)\n",
    "    \n",
    "    df.apply(lambda x: x['links'].extend(x['pests_and_disorders' ]), axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "    return df\n",
    "\n",
    "df      = infoFruits()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def infoVeggies():\n",
    "    # -------------------------------------------- Veggies information\n",
    "    print(f'Merging veggies information...')\n",
    "    FILE_NAME = 'veggieItems_new.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description tips images pests_and_disorders\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoVeggies'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    \n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title'       ,\n",
    "        'tips'  : 'management'  ,\n",
    "        'images': 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df['pests_and_disorders'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'problem' , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['problem']\n",
    "        } for i in r['pests_and_disorders'] if len(i['problem']) > 0], axis = 1)\n",
    "\n",
    "    df.apply(lambda x: x['links'].extend(x['pests_and_disorders' ]), axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = infoVeggies()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def infoFlowers():\n",
    "    # -------------------------------------------- Flowers information\n",
    "    print(f'Merging flowers information...')\n",
    "    FILE_NAME = 'plantFlowerItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url identification optimum_conditions pests_and_disorders images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoFlowers'\n",
    "    df['description'    ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'              : 'title'       ,\n",
    "        'optimum_conditions': 'management'  ,\n",
    "        'images'            : 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df['pests_and_disorders'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'problem' , \n",
    "            'src'   : i['link'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['problem']\n",
    "        } for i in r['pests_and_disorders'] if len(i['problem']) > 0], axis = 1)\n",
    "\n",
    "    df.apply(lambda x: x['links'].extend(x['pests_and_disorders' ]), axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = infoFlowers()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def _clean(text):\n",
    "    '''\n",
    "    Fix encodings and remove escape and redundant whitespace characters from text.\n",
    "    '''\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "colsVector = ['title', 'description', 'identification', 'development', 'damage', 'management']\n",
    "for c in colsVector:\n",
    "    finalDf[c] = finalDf[c].apply(_clean)\n",
    "\n",
    "print(f'Fix encodings and remove escape and redundant whitespace characters from text.')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "print(f'Final dataframe shape: {finalDf.shape    }')\n",
    "print(f'FINISHED')\n",
    "\n",
    "finalDf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IPM data - April 2022 Scrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "['FruitVegCulturalItems.json',\n",
    " 'GardenControlsPestItems.json',\n",
    " 'GardenControlsPesticideItems.json',\n",
    " 'PestNotes.json',\n",
    " 'QuickTips.json',\n",
    " 'Videos.json',\n",
    " 'WeedIdItems.json']\n",
    "'''\n",
    "_PATH = '../data/uc-ipm/updated-Apr2022/'\n",
    "DATA_FILE_NAMES = sorted(os.listdir(_PATH))\n",
    "DATA_FILE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']\n",
    "\n",
    "def infoFruitVegCultural():\n",
    "    # -------------------------------------------- Fruit and veggie cultural tips\n",
    "    print(f'Merging fruit and veggie cultural tips..')\n",
    "    FILE_NAME = 'FruitVegCulturalItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description images tips_table\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoFruitVegCultural'        \n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title',\n",
    "        'images': 'links'\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df['tips_table'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'problem' , \n",
    "            'src'   : r['url'] , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['header']\n",
    "        } for i in r['tips_table'] if 'header' in i and len(i['header']) > 0], axis = 1)\n",
    "\n",
    "    df.apply(lambda x: x['links'].extend(x['tips_table' ]), axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df      = infoFruitVegCultural()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def infoPestControl():\n",
    "    # -------------------------------------------- Garden pest control\n",
    "    print(f'Merging garden pest control information...')\n",
    "    FILE_NAME = 'GardenControlsPestItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoPestControl'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title',\n",
    "        'images': 'links'\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df['links'].apply(lambda d: d if isinstance(d, list) else [])\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'                , \n",
    "            'src'   : i.get('src'       , ''), \n",
    "            'link'  : i.get('link'      , ''),\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df      = infoPestControl()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def infoPesticideControl():\n",
    "    # -------------------------------------------- Garden pesticide control\n",
    "    print(f'Merging garden pesticide control information...')\n",
    "    FILE_NAME = 'GardenControlsPesticideItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    active_ingredient url pesticide_type information\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'infoPesticideControl'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "    \n",
    "    df['title'          ] = df[['active_ingredient', 'pesticide_type']].agg(' - '.join, axis=1)\n",
    "    df['description'    ] = df['information'].str[0].apply(lambda x: x['associated_pests'])\n",
    "    df['links'          ] = [[] for _ in range(len(df))]\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = infoPesticideControl()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def pestsNotes():\n",
    "    # -------------------------------------------- Pests IPM\n",
    "    print(f'Merging pests notes...')\n",
    "    FILE_NAME = 'PestNotes.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name urlPestNote descriptionPestNote lifecyclePestNote damagePestNote managementPestNote imagePestNote tablePestNote\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'pestsNotes'\n",
    "    df['identification' ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'urlPestNote'           : 'url'         ,\n",
    "        'name'                  : 'title'       ,\n",
    "        'descriptionPestNote'   : 'description' ,\n",
    "        'lifecyclePestNote'     : 'development' ,\n",
    "        'damagePestNote'        : 'damage'      ,\n",
    "        'managementPestNote'    : 'management'  ,\n",
    "        'imagePestNote'         : 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df      = pestsNotes()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def pestsQuickTips():\n",
    "    # -------------------------------------------- Quick tips on pests\n",
    "    print(f'Merging pests quick notes...')\n",
    "    FILE_NAME = 'QuickTips.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name urlQuickTip contentQuickTips imageQuickTips\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'        ] = 'pestsQuickTips'\n",
    "    df['identification'] = ''\n",
    "    df['development'   ] = ''\n",
    "    df['damage'        ] = ''\n",
    "    df['management'    ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'urlQuickTip'           : 'url'         ,\n",
    "        'name'                  : 'title'       ,\n",
    "        'contentQuickTips'      : 'description' ,\n",
    "        'imageQuickTips'        : 'links'       ,\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : i['link'] ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "    \n",
    "    return df\n",
    "\n",
    "df      = pestsQuickTips()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "def pestsVideos():\n",
    "    # -------------------------------------------- Videos of UC IPM YouTube data\n",
    "    print(f'Merging UC IPM YouTube data...')\n",
    "    FILE_NAME = 'Videos.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    title url description\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'pestsVideos'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df['links'          ] = [[] for _ in range(len(df))]\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = pestsVideos()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape    }')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "\n",
    "def pestsWeed():\n",
    "    # -------------------------------------------- Weed related pests\n",
    "    print(f'Merging weed related pests...')\n",
    "    FILE_NAME = 'WeedIdItems.json'\n",
    "    df = pd.read_json(_PATH + FILE_NAME)\n",
    "    '''\n",
    "    columns in source:\n",
    "    name url description images\n",
    "    final schema:\n",
    "    source url title description identification development damage management links\n",
    "    '''\n",
    "\n",
    "    df['source'         ] = 'pestsWeed'\n",
    "    df['identification' ] = ''\n",
    "    df['development'    ] = ''\n",
    "    df['damage'         ] = ''\n",
    "    df['management'     ] = ''\n",
    "\n",
    "    df.rename(columns = {\n",
    "        'name'  : 'title',\n",
    "        'images': 'links'\n",
    "    }, inplace = True)\n",
    "\n",
    "    df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : 'image'   , \n",
    "            'src'   : i['src']  , \n",
    "            'link'  : ''        ,\n",
    "            'title' : r['title'] + ' - ' + i['caption']\n",
    "        } for i in r['links'] if len(i['caption']) > 0], axis = 1)\n",
    "\n",
    "    df = df[cols]\n",
    "\n",
    "    return df\n",
    "\n",
    "df      = pestsWeed()\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "def _clean(text):\n",
    "    '''\n",
    "    Fix encodings and remove escape and redundant whitespace characters from text.\n",
    "    '''\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "colsVector = ['title', 'description', 'identification', 'development', 'damage', 'management']\n",
    "for c in colsVector:\n",
    "    finalDf[c] = finalDf[c].apply(_clean)\n",
    "\n",
    "print(f'Fix encodings and remove escape and redundant whitespace characters from text.')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "print(f'Final dataframe shape: {finalDf.shape    }')\n",
    "print(f'FINISHED')\n",
    "\n",
    "finalDf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AskExtension Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "PATH = '../data/askextension/2020-08-20/'\n",
    "FILE_NAMES = [PATH + f for f in sorted(os.listdir(PATH))]\n",
    "\n",
    "with open(FILE_NAMES[0]) as f:\n",
    "    f = json.load(f)\n",
    "    print(json.dumps(f[0], indent = 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "\n",
    "from string import punctuation as pn\n",
    "\n",
    "# Modify STATE_FILTER and MIN_WORD_COUNT variables accordingly\n",
    "STATE_FILTER    = ['California']\n",
    "MIN_WORD_COUNT  = 3\n",
    "\n",
    "ASKEXTENSION_QUESTION_URL = 'https://ask2.extension.org/kb/faq.php?id='\n",
    "\n",
    "# Combines the data files into one and returns it.\n",
    "df = pd.DataFrame()\n",
    "for f in FILE_NAMES:\n",
    "    df = pd.concat([df, pd.read_json(f)], ignore_index = True, axis = 0)\n",
    "\n",
    "df['source'] = 'askExtension'\n",
    "\n",
    "# Convert 'faq-id' to str type\n",
    "df['faq-id'] = df['faq-id'].astype(str)\n",
    "\n",
    "# Leave tickets from California state\n",
    "df = df[df['state'].isin(STATE_FILTER)]\n",
    "\n",
    "# Add the URL and leave blank URL for questions with no ID\n",
    "df['url'] = [\n",
    "    f\"{ASKEXTENSION_QUESTION_URL}{ticket_no}\" if len(ticket_no) == 6 else \"\"\n",
    "    for ticket_no in df['title'].str.split('#').str[-1]\n",
    "]\n",
    "\n",
    "# Add the ticket number from title and leave blank for questions without\n",
    "df['ticket-no'] = [\n",
    "    ticket_no if len(ticket_no) == 6 else \"\"\n",
    "    for ticket_no in df['title'].str.split('#').str[-1]\n",
    "]\n",
    "\n",
    "df.rename(columns = {'faq-id': 'faq_id', 'ticket-no': 'ticket_no'}, inplace = True)\n",
    "\n",
    "def _clean(text):\n",
    "    '''\n",
    "    Fix encodings and remove escape and redundant whitespace characters from text.\n",
    "\n",
    "    Examples with non-ascii characters - 110358, 147160\n",
    "    Examples with redundant whitespace - 117069, 127760\n",
    "\n",
    "    See: https://stackoverflow.com/a/53821967/5480536\n",
    "    '''\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def _transform_answer(answer_dict):\n",
    "    '''\n",
    "    Convert answer field from a dictionary to a list.\n",
    "    '''\n",
    "    answers = [{}] * len(answer_dict)\n",
    "    \n",
    "    for k, v in answer_dict.items():\n",
    "        # clean the response up\n",
    "        v = {\n",
    "            'type'  : 'answer'  ,\n",
    "            'src'   : ''        , \n",
    "            'link'  : ''        ,\n",
    "            'title' : _clean(v['response']),\n",
    "        }\n",
    "        answers[int(k) - 1] = v\n",
    "    \n",
    "    return answers\n",
    "\n",
    "# Transform answer for consistency with IPM data\n",
    "df['links'] = df['answer'].apply(_transform_answer)\n",
    "df['links'] = df.apply(lambda r: [\n",
    "        {\n",
    "            'type'  : i['type'] , \n",
    "            'src'   : r['url']  , \n",
    "            'link'  : ''        ,\n",
    "            'title' : i['title']\n",
    "        } for i in r['links'] if len(i['title']) > 0], axis = 1)\n",
    "\n",
    "# Strip all spaces and remove non-ascii characters from text fields\n",
    "for column in ['state', 'title', 'question']:\n",
    "    df[column] = df[column].apply(_clean)\n",
    "\n",
    "def _transform_title(title):\n",
    "    '''\n",
    "    Remove question ID from title, and append '.' in the end\n",
    "    if no punctuation was detected.\n",
    "\n",
    "    Example with '#' - 437259\n",
    "    Example with '...' - 437264\n",
    "    '''\n",
    "    title = ''.join(title.split('#')[:-1]).strip().strip('...')\n",
    "    \n",
    "    # add a '.' if it does not yet end with a punctuation\n",
    "    title = title if (title and title[-1] in pn) else title + '.'\n",
    "    \n",
    "    return title\n",
    "\n",
    "# Clean ID and '...' from title, and append punctuation if not present\n",
    "df['title'] = df['title'].apply(_transform_title)\n",
    "\n",
    "def _merge_title_question(df):\n",
    "    '''\n",
    "    Create new column from questions and title,\n",
    "    but only if it is not already exactly in the question.\n",
    "    '''\n",
    "    titles      = df['title'    ].tolist()\n",
    "    questions   = df['question' ].tolist()\n",
    "    \n",
    "    tqs = [\n",
    "        question\n",
    "        if (title and question.startswith(title[:-1]))\n",
    "        else title + \" \" + question\n",
    "        for (title, question) in zip(titles, questions)\n",
    "    ]\n",
    "\n",
    "    return tqs\n",
    "\n",
    "# Create new column from `title` and `question`, or only question\n",
    "# if title is exactly the question     \n",
    "df['description'] = _merge_title_question(df)\n",
    "    \n",
    "# Remove questions with small number words in title-question\n",
    "if MIN_WORD_COUNT:\n",
    "    df = df[df['description'].str.split().str.len() > MIN_WORD_COUNT]\n",
    "\n",
    "df = df.loc[:, ['source', 'url', 'title', 'description', 'links']]\n",
    "df.sample(5)\n",
    "\n",
    "cols = ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']\n",
    "'''\n",
    "columns in source:\n",
    "source url name description links\n",
    "final schema:\n",
    "source url title description identification development damage management links    \n",
    "'''\n",
    "df['identification' ] = ''\n",
    "df['development'    ] = ''\n",
    "df['damage'         ] = ''\n",
    "df['management'     ] = ''\n",
    "df = df[cols]\n",
    "\n",
    "finalDf = pd.concat([finalDf, df], ignore_index = True, axis = 0)\n",
    "print(f'Final dataframe shape: {finalDf.shape}')\n",
    "print(f'------------------------------------------------')\n",
    "\n",
    "finalDf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding text fields into vectors and stripping text fields for saving into ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "os.environ['STAGE'          ] = 'dev'\n",
    "os.environ['ES_USERNAME'    ] = 'elastic'\n",
    "os.environ['ES_PASSWORD'    ] = 'changeme'\n",
    "os.environ['TF_CACHE_DIR'   ] = '/var/tmp/models'\n",
    "## select the environment for ingestion\n",
    "os.environ['ES_HOST'    ] = 'http://localhost:9200/'\n",
    "# os.environ['ES_HOST'    ] = 'https://dev.es.chat.ask.eduworks.com/'\n",
    "# os.environ['ES_HOST'    ] = 'https://qa.es.chat.ask.eduworks.com/'\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE      = 1\n",
    "ROLLING_SIZE    = 3\n",
    "\n",
    "colsVector = ['title', 'description', 'identification', 'development', 'damage', 'management']\n",
    "print(f'Final DF: Transforming columns - {colsVector} and links titles.')\n",
    "\n",
    "from spacy.lang.en import English \n",
    "\n",
    "nlp = English()\n",
    "nlp.add_pipe('sentencizer')\n",
    "raw_text = finalDf.iloc[0]['description']\n",
    "\n",
    "print(f'STARTING TRANSFORMING')\n",
    "c_items = []\n",
    "for i, r in finalDf.iterrows():\n",
    "    r_texts = []\n",
    "    for c in colsVector:\n",
    "        t = r[c]\n",
    "        \n",
    "        doc = nlp(t)\n",
    "        \n",
    "        ts = [sent for sent in doc.sents]\n",
    "        if len(ts) == 0:\n",
    "            continue\n",
    "        else:\n",
    "            chunks, chunk_size, roll_size = len(ts), CHUNK_SIZE, ROLLING_SIZE\n",
    "            ts = [ts[i1:i1+chunk_size+(roll_size - 1)] for i1 in range(0, chunks - (roll_size - 1), chunk_size)]\n",
    "            ts = [{'text': ' '.join([l2.text for l2 in l1]), 'name': c + '_' + str(i1), 'start': l1[0].start_char, 'end': l1[-1].end_char} for i1, l1 in enumerate(ts)]\n",
    "                \n",
    "        r_texts.extend(ts)\n",
    "    \n",
    "    ts = [r['title'] + ' - ' + i1['title'] for i1 in r['links']]\n",
    "    if len(ts) == 0:\n",
    "        c_items.append(r_texts)\n",
    "        if (i+1) % 500 == 0:\n",
    "            print(f'Finished transforming of {i+1} rows of dataframe')\n",
    "        continue\n",
    "\n",
    "    for i1, v in enumerate(ts):\n",
    "        r_texts.append({'text': v, 'name': 'links_' + str(i1), 'start': 0, 'end': -1})\n",
    "    \n",
    "    c_items.append(r_texts)\n",
    "\n",
    "    if (i+1) % 500 == 0:\n",
    "        print(f'Finished transforming of {i+1} rows of dataframe')\n",
    "\n",
    "print(f'Finished transforming of {i+1} rows of dataframe')\n",
    "print(f'FINISHED TRANSFORMING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'START REPLACING')\n",
    "\n",
    "texts = [r1['text'] for r in c_items for r1 in r]\n",
    "texts_modified = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    tokens = config.tokenizer(text)\n",
    "    modified = \"\"\n",
    "    replace = False\n",
    "    for token in tokens:\n",
    "        t = token.text.lower()\n",
    "        \n",
    "        if t in config.synonym_dict:\n",
    "            modified += config.synonym_dict[t]\n",
    "            modified += token.whitespace_\n",
    "            replace = True\n",
    "        else:\n",
    "            modified += token.text_with_ws\n",
    "    \n",
    "    if not replace:\n",
    "        modified = text\n",
    "    texts_modified.append(modified)\n",
    "\n",
    "    if (i+1) % 10000 == 0:\n",
    "        print(f'Finished replacing synonyms of {i+1} items of sentences')\n",
    "\n",
    "print(f'Finished replacing synonyms of {i+1} items of sentences')\n",
    "print(f'FINISHED REPLACING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for invalid links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_ucipm = 0\n",
    "count_askextension = 0\n",
    "for i, r in finalDf.iterrows():\n",
    "    if len(r['url']) < 10:\n",
    "        print(f'Source with no main link at row {i} of data frame, main link - {r[\"url\"]}.')\n",
    "    links = r['links']\n",
    "    no_link = False\n",
    "    show_main_url = False\n",
    "    for l in links:\n",
    "        url = r['url']\n",
    "        if len(l['src']) < 10:\n",
    "            no_link = True\n",
    "            if not show_main_url:\n",
    "                show_main_url = True\n",
    "                print(f'Links at {url}')\n",
    "            print(l)\n",
    "    if no_link:\n",
    "        if r['source'] == 'askExtension':\n",
    "            count_askextension += 1\n",
    "        else:\n",
    "            count_ucipm += 1\n",
    "\n",
    "print(f'Number of sources from AskExtension with no link urls - {count_askextension}')\n",
    "print(f'Number of sources from UC IPM with no link urls - {count_ucipm}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding textual data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "print(f'STARTING EMBEDDING')\n",
    "\n",
    "finalDf['vectors'] = np.empty((len(finalDf), 0)).tolist()\n",
    "\n",
    "# TF HUB model\n",
    "# vectors   = config.embed(texts_modified).numpy().tolist()\n",
    "    \n",
    "# Sentence Encoder model        \n",
    "vectors = config.embed.encode(\n",
    "    sentences           = texts_modified,\n",
    "    batch_size          = BATCH_SIZE    ,\n",
    "    show_progress_bar   = True\n",
    ").tolist()\n",
    "\n",
    "index = 0\n",
    "for i, r in enumerate(c_items):\n",
    "    for i1, r1 in enumerate(r):\n",
    "        r1['vector'] = vectors[index]\n",
    "        r1.pop('text')\n",
    "        index += 1\n",
    "\n",
    "print(f'FINISHED EMBEDDING')\n",
    "\n",
    "finalDf['vectors'] = c_items\n",
    "print(f'The number of vectors to be ingested: {len([r1[\"vector\"] for r in finalDf[\"vectors\"] for r1 in r])}')        \n",
    "finalDf.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ingesting data into ES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different embedding sizes depending on the models\n",
    "# VECTOR_SIZE = 384\n",
    "# VECTOR_SIZE = 512\n",
    "VECTOR_SIZE = 768\n",
    "\n",
    "mapping  = {\n",
    "    \"settings\": {\"number_of_shards\": 2, \"number_of_replicas\": 1},\n",
    "    \"mappings\": {\n",
    "        \"dynamic\"   : \"false\",\n",
    "        \"_source\"   : {\"enabled\": \"true\"},\n",
    "        \"properties\": {\n",
    "            \"source\"        : {\"type\": \"keyword\", \"index\": \"true\" , \"ignore_above\": 32766},\n",
    "            \"url\"           : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "\n",
    "            \"title\"         : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"description\"   : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"identification\": {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"development\"   : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"damage\"        : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"management\"    : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "            \"vectors\"       : {\n",
    "                \"type\"      : \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"vector\": {\n",
    "                        \"type\": \"dense_vector\", \n",
    "                        \"dims\": VECTOR_SIZE\n",
    "                    },\n",
    "                    \"name\"  : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "                    \"start\" : {\"type\": \"integer\"                                         },\n",
    "                    \"end\"   : {\"type\": \"integer\"                                         },\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            \"links\"         : {\n",
    "                \"type\"      : \"nested\",\n",
    "                \"properties\": {\n",
    "                    \"type\"  : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "                    \"src\"   : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "                    \"link\"  : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766},\n",
    "                    \"title\" : {\"type\": \"keyword\", \"index\": \"false\", \"ignore_above\": 32766}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "final_json = finalDf.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import parallel_bulk\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "# increase the timeout if necessary\n",
    "es_client = Elasticsearch([config.es_host], http_auth=(config.es_username, config.es_password), timeout = 20)\n",
    "\n",
    "es_client.indices.delete(\n",
    "    index   = config.es_combined_index, \n",
    "    ignore  = 404)\n",
    "es_client.indices.create(\n",
    "    index       = config.es_combined_index  , \n",
    "    settings    = mapping['settings']       , \n",
    "    mappings    = mapping['mappings']       )\n",
    "# play with chunk size parameter for timed out problem\n",
    "deque(parallel_bulk(es_client, actions = final_json, index = config.es_combined_index, max_chunk_bytes = 5 * 1024 * 1024), maxlen = 0)\n",
    "\n",
    "es_client.indices.refresh()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('askchatbot-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "362d59c0cf6dbeab3abcbfc8685ab4c27b49db463d853836c10c4cab9bbbe211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

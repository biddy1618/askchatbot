{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ES playground"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing ES - playing with functions to handle requests from ChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "os.environ['ES_USERNAME'    ] = 'elastic'\n",
    "os.environ['ES_PASSWORD'    ] = 'changeme'\n",
    "os.environ['ES_HOST'        ] = 'http://localhost:9200/'\n",
    "\n",
    "import config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying for nested fields filtering IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# inputs from the users for querying\n",
    "question    = 'Problems with my plant kales'\n",
    "slots       = None\n",
    "slots       = [\n",
    "    # 'defoliated small caterpillars small',\n",
    "    # 'oak tree caterpillars',\n",
    "    'plant kales'\n",
    "]\n",
    "filter_ids = None\n",
    "# filter_ids = ['Bg4Wt38B_ISSR2mEO2MB']\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# prepocessing of the text queries\n",
    "\n",
    "def _synonym_replace(text):\n",
    "    index = 0\n",
    "\n",
    "    tokens = config.tokenizer(text)\n",
    "    text_modified = \"\"\n",
    "    for token in tokens:\n",
    "        t = token.text.lower()\n",
    "\n",
    "        if t in config.synonym_dict:\n",
    "            text_modified += config.synonym_dict[t]\n",
    "            text_modified += token.whitespace_\n",
    "        else:\n",
    "            text_modified += token.text_with_ws\n",
    "\n",
    "    return text_modified    \n",
    "\n",
    "question = _synonym_replace(question)\n",
    "\n",
    "if slots:\n",
    "    question = '. '.join([question] + [_synonym_replace(s) for s in slots])\n",
    "\n",
    "# TF HUB model\n",
    "# query_vector = config.embed([question]).numpy()[0]\n",
    "\n",
    "# Sentence Encoder model\n",
    "query_vector = config.embed.encode([question], show_progress_bar = False)[0]\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# querying the ES\n",
    "\n",
    "ES_SEARCH_SIZE      = 100\n",
    "index               = 'combined'\n",
    "vector_name         = 'vectors.vector'\n",
    "source_query        = {'includes': ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']}\n",
    "source_nested       = {'includes': ['vectors.name', 'vectors.start', 'vectors.end']}\n",
    "score_mod           = 'max'\n",
    "\n",
    "cos     = f'cosineSimilarity(params.query_vector, \"{vector_name}\") + 1.0'\n",
    "script  =  {\"source\": cos, \"params\": {\"query_vector\": query_vector}}\n",
    "\n",
    "path = vector_name.split('.')[0]\n",
    "query_nested = {\n",
    "    \"bool\": {\n",
    "        \"must\": {\"nested\": {\n",
    "                \"score_mode\": score_mod ,\n",
    "                \"path\"      : path      ,\n",
    "                \"inner_hits\": {\"size\": 3, \"name\": \"nested\", \"_source\": source_nested},\n",
    "                \"query\"     : {\"function_score\": {\"script_score\": {\"script\": script}}}}\n",
    "        },\n",
    "        \"filter\"    : [],\n",
    "        # \"must_not\"  : []\n",
    "}}\n",
    "\n",
    "# for filtering the IDs\n",
    "if filter_ids is not None:\n",
    "    query_nested['bool']['filter'   ].append({'ids'     : {'values': filter_ids}})\n",
    "# for querying only AskExtension source\n",
    "# query_nested['bool']['filter'   ].append({'match'   : {'source': 'askExtension'}})\n",
    "# for querying only IPM sources\n",
    "# query_nested['bool']['must_not' ].append({'match'   : {'source': 'askExtension'}})\n",
    "\n",
    "response = await config.es_client.search(\n",
    "    index   = index         ,\n",
    "    query   = query_nested  ,\n",
    "    size    = ES_SEARCH_SIZE,\n",
    "    _source = source_query\n",
    ")\n",
    "\n",
    "\n",
    "hits = []\n",
    "\n",
    "for h1 in response['hits']['hits']:\n",
    "    top_scores = []\n",
    "    for h2 in h1['inner_hits']['nested']['hits']['hits']: \n",
    "        top_scores.append({'score': h2['_score'] - 1, 'source': h2['_source']})\n",
    "    \n",
    "    h1['_source']['top_scores'] = top_scores\n",
    "    h1['_source']['_id']        = h1['_id']\n",
    "    h1['_source']['_score']     = h1['_score'] - 1\n",
    "    hits.append(h1['_source'])\n",
    "    \n",
    "# ---------------------------------------------------------------------------------------------------------\n",
    "# processing the results\n",
    "\n",
    "ES_ASK_WEIGHT   = 0.4\n",
    "ES_CUT_OFF      = 0.4\n",
    "FILTER          = True\n",
    "\n",
    "for h in hits: \n",
    "    if h['source'] == 'askExtension': \n",
    "        h['_score'] *= ES_ASK_WEIGHT\n",
    "\n",
    "    \n",
    "if FILTER:\n",
    "    hits = [h for h in hits if h['_score'] > ES_CUT_OFF]\n",
    "\n",
    "hits = [h for h in hits if len(h['url']) > 0]\n",
    "\n",
    "filter_ids = [h['_id'] for h in hits]\n",
    "hits = sorted(hits, key = lambda h: h['_score'], reverse = True)\n",
    "\n",
    "    \n",
    "for item in hits[:10]:\n",
    "    for k, v in item.items():\n",
    "        if v and k not in ['top_scores', 'links', '_score']:\n",
    "            print(f'{k:<20}: {v[:100] if isinstance(v, str) else v}...')\n",
    "        elif k == '_score':\n",
    "            print(f'{k:<20}: {v:.3f}')\n",
    "        elif k == 'top_scores':\n",
    "            top_scores  = [v1['score'] for v1 in v          ]\n",
    "            top_names   = [v1['source']['name'] for v1 in v ]\n",
    "            print(f'{k:<20}: {\"| \".join([str(i1+1) + \" \" + v1[0] + \" score: \" + str(v1[1])[:5] for i1, v1 in enumerate(list(zip(top_names, top_scores)))])}')\n",
    "            for i1, name in enumerate(top_names):\n",
    "                name, index = name.split('_')\n",
    "                if name == 'links':\n",
    "                    name = item['links'][int(index)]['title']\n",
    "                else:\n",
    "                    name = item[name]\n",
    "                print(f'{(\"top_score_\"+str(i1+1)):<20}: {name}')\n",
    "    print('\\n')        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug cell\n",
    "\n",
    "The flow of ES query is as follows:\n",
    "\n",
    "Simple query against every possible field:\n",
    "```python\n",
    "(hits, hits_slots) = await _handle_es_query(question, slots)\n",
    "```\n",
    "\n",
    "Get response for chat from ES query:\n",
    "```python\n",
    "res = _get_text(hits)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _cos_sim_query(\n",
    "    query_vector    : np.ndarray        ,\n",
    "    filter_ids      : List[str] = None  ,\n",
    "    ) -> dict:\n",
    "    '''Exectute vector search in ES based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        query_vector    (np.ndarray): Query vector.\n",
    "        filter_ids      (List[str]) : Filter results based on the IDs given. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict: Return hits.\n",
    "    '''\n",
    "    vector_name     = 'vectors.vector'\n",
    "    source_nested   = {'includes': ['vectors.name', 'vectors.start', 'vectors.end']}\n",
    "    \n",
    "    cos     = f'cosineSimilarity(params.query_vector, \"{vector_name}\") + 1.0'\n",
    "    script  = {\"source\": cos, \"params\": {\"query_vector\": query_vector}}\n",
    "    \n",
    "    source_query = {'includes': ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']}\n",
    "    \n",
    "    path = vector_name.split('.')[0]\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\"nested\": {\n",
    "                        \"score_mode\": \"max\" ,\n",
    "                        \"path\"      : path  ,\n",
    "                        \"inner_hits\": {\"size\": 3, \"name\": \"nested\", \"_source\": source_nested},\n",
    "                        \"query\"     : {\"function_score\": {\"script_score\": {\"script\": script}}}}\n",
    "            },\n",
    "            \"filter\"    : [],\n",
    "            \"must_not\"  : []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if filter_ids is not None:\n",
    "        query['bool']['filter'].append({'ids': {'values': filter_ids}})\n",
    "\n",
    "    response = await config.es_client.search(\n",
    "        index   = config.es_combined_index  ,\n",
    "        query   = query                     ,\n",
    "        size    = config.es_search_size     ,\n",
    "        _source = source_query\n",
    "    )\n",
    "\n",
    "    hits = []\n",
    "\n",
    "    for h1 in response['hits']['hits']:\n",
    "        top_scores = []\n",
    "\n",
    "        for h2 in h1['inner_hits']['nested']['hits']['hits']:\n",
    "            top_scores.append({'score': h2['_score'] - 1, 'source': h2['_source']})\n",
    "        \n",
    "        h1['_source']['top_scores'  ] = top_scores\n",
    "        h1['_source']['_id'         ] = h1['_id'    ]\n",
    "        h1['_source']['_score'      ] = h1['_score' ] - 1\n",
    "        \n",
    "        hits.append(h1['_source'])\n",
    "\n",
    "    return hits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _handle_es_query(\n",
    "    query       : str               ,\n",
    "    slots       : List[str] = None  ,\n",
    "    filter_ids  : List[str] = None  ,\n",
    "    ) -> list:\n",
    "    '''Perform search in ES base.\n",
    "\n",
    "    Args:\n",
    "        query       (str)       : Query statement.\n",
    "        slots       (List[str]) : Additional entity queries. Defaults to None.\n",
    "        filter_ids  (List[str]) : IDs of docs that should be considered. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        list: return list of hits. \n",
    "    '''\n",
    "    \n",
    "    def _synonym_replace(text):\n",
    "        tokens = config.tokenizer(text)\n",
    "        text_modified = \"\"\n",
    "        for token in tokens:\n",
    "            t = token.text.lower()\n",
    "                \n",
    "            if t in config.synonym_dict:\n",
    "                text_modified += config.synonym_dict[t]\n",
    "                text_modified += token.whitespace_\n",
    "            else:\n",
    "                text_modified += token.text_with_ws\n",
    "\n",
    "        return text_modified    \n",
    "        \n",
    "    query = _synonym_replace(query)\n",
    "\n",
    "    if slots:\n",
    "        query = '. '.join([query] + [_synonym_replace(s) for s in slots])\n",
    "\n",
    "    # TF HUB model\n",
    "    # query_vector = config.embed([query]).numpy()[0]\n",
    "\n",
    "    # Sentence Encoder model\n",
    "    query_vector = config.embed.encode([query], show_progress_bar = False)[0]\n",
    "\n",
    "    hits = await _cos_sim_query(\n",
    "        query_vector    = query_vector,\n",
    "        filter_ids      = filter_ids\n",
    "    )\n",
    "\n",
    "    return hits\n",
    "\n",
    "hits = await _handle_es_query(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _handle_es_result(\n",
    "    hits    : list,\n",
    "    filter  : bool = True\n",
    "    ) -> Tuple[list, list]:\n",
    "    '''Process the ES query results (like filtering, reweighting, etc).\n",
    "\n",
    "    Args:\n",
    "        hits    (list): Results from ES query.\n",
    "        filter  (bool): If cut off filter should be applied. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[list, list]: filtered and processed ES query results\n",
    "    '''\n",
    "\n",
    "    for h in hits: \n",
    "        if h['source'] == 'askExtension': \n",
    "            h['_score'] *= config.es_ask_weight\n",
    "    \n",
    "    hits = [h for h in hits if len(h['url']) > 0]\n",
    "    \n",
    "    if filter:\n",
    "        hits = [h for h in hits if h['_score'] > config.es_cut_off]\n",
    "    \n",
    "    filter_ids = [h['_id'] for h in hits]\n",
    "    hits = sorted(hits, key = lambda h: h['_score'], reverse = True)\n",
    "\n",
    "    return hits, filter_ids\n",
    "\n",
    "hits, filter_ids = _handle_es_result(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable for the new view\n",
    "# def _format_result(hit) -> dict:\n",
    "\n",
    "#     score           = hit.get('_score'        , 0.0   )\n",
    "#     source          = hit.get('source'        , None  )\n",
    "#     url             = hit.get('url'           , None  )\n",
    "#     title           = hit.get('title'         , None  )\n",
    "#     description     = hit.get('description'   , None  )\n",
    "#     identification  = hit.get('identification', None  )\n",
    "#     development     = hit.get('development'   , None  )\n",
    "#     damage          = hit.get('damage'        , None  )\n",
    "#     management      = hit.get('management'    , None  )\n",
    "\n",
    "#     def _format_scores(hit = None):\n",
    "#         scores = hit['top_scores']\n",
    "#         scores_dict = {}\n",
    "        \n",
    "#         for i, s in enumerate(scores):\n",
    "#             s1 = {'score': s['score']}\n",
    "\n",
    "#             name, index = s['source']['name'    ].split('_')\n",
    "            \n",
    "#             start       = s['source']['start'   ]\n",
    "#             end         = s['source']['end'     ]\n",
    "#             if end > config.es_field_limit:\n",
    "#                 start   = config.es_field_limit - 50\n",
    "#                 end     = config.es_field_limit\n",
    "            \n",
    "#             s1['field'] = name\n",
    "            \n",
    "#             if name == 'links': s1['text'] = hit['title'] + ' - ' + hit[name][int(index)]['title']\n",
    "#             else:               s1['text'] = hit[name   ][start:end]\n",
    "            \n",
    "#             scores_dict['top_score_' + str(i+1)] = s1\n",
    "        \n",
    "#         return scores_dict\n",
    "\n",
    "#     res = {}\n",
    "#     if config.debug:\n",
    "#         res['title'] = (\n",
    "#             f'<p><em>{title}</em>'\n",
    "#             f'</br>(score: {score:.2f})</br>'\n",
    "#             f'(source: <a href=\"{url}\" target=\"_blank\">{source}</a>)</p>')\n",
    "#     else:\n",
    "#         res['title'] = (\n",
    "#             f'<p><em>{title}</em>'\n",
    "#             f'</br>(source: <a href=\"{url}\" target=\"_blank\">{source}</a>)</p>')\n",
    "    \n",
    "#     res['description'] = ''\n",
    "#     if description:\n",
    "#         res['description'] += (f'<p><strong>Details</strong>: {description[:100]}</p></br>'             )\n",
    "#     if damage:\n",
    "#         res['description'] += (f'<p><strong>Damage</strong>: {damage[:100]}</p></br>'                   )\n",
    "#     if identification:\n",
    "#         res['description'] += (f'<p><strong>Identification</strong>: {identification[:100]}</p></br>'   )\n",
    "#     if development:\n",
    "#         res['description'] += (f'<p><strong>Development</strong>: {development[:100]}</p></br>'         )\n",
    "#     if management:\n",
    "#         res['description'] += (f'<p><strong>Management</strong>: {management[:100]}</p></br>'           )\n",
    "    \n",
    "#     res['meta'  ] = {}\n",
    "#     res['meta'  ]['url'   ] = url\n",
    "#     res['meta'  ]['title' ] = title\n",
    "#     res['meta'  ]['source'] = source\n",
    "#     res['meta'  ]['scores'] = _format_scores(hit)\n",
    "        \n",
    "#     return res\n",
    "\n",
    "\n",
    "# Enable for the new view\n",
    "def _format_result(hit) -> dict:\n",
    "    \n",
    "    score           = hit.get('_score'          , 0.0   )\n",
    "    source          = hit.get('source'          , None  )\n",
    "    url             = hit.get('url'             , None  )\n",
    "    title           = hit.get('title'           , None  )\n",
    "    description     = hit.get('description'     , None  )\n",
    "    identification  = hit.get('identification'  , None  )\n",
    "    development     = hit.get('development'     , None  )\n",
    "    damage          = hit.get('damage'          , None  )\n",
    "    management      = hit.get('management'      , None  )\n",
    "    links           = hit.get('links'           , None  )\n",
    "\n",
    "    def _format_images(links = None):\n",
    "        images = []\n",
    "        \n",
    "        for l in links:\n",
    "            if l['type'] == 'image':\n",
    "                image = {\n",
    "                    'src'   : l['src'  ],\n",
    "                    'link'  : l['link' ],\n",
    "                    'title' : l['title']\n",
    "                }\n",
    "\n",
    "                images.append(image)\n",
    "        \n",
    "        return images\n",
    "\n",
    "    def _format_scores(hit = None):\n",
    "        scores = hit['top_scores']\n",
    "        scores_dict = {}\n",
    "        \n",
    "        for i, s in enumerate(scores):\n",
    "            s1 = {'score': f'{s[\"score\"]:.2f}'}\n",
    "            \n",
    "            if s['score'] < config.es_cut_off:\n",
    "                break\n",
    "\n",
    "            name, index = s['source']['name'    ].split('_')\n",
    "            \n",
    "            start       = s['source']['start'   ]\n",
    "            end         = s['source']['end'     ]\n",
    "            if end > config.es_field_limit:\n",
    "                start   = config.es_field_limit - 50\n",
    "                end     = config.es_field_limit\n",
    "            \n",
    "            s1['field'] = name\n",
    "            \n",
    "            if name == 'links':\n",
    "                link = hit[name][int(index)]\n",
    "                s1['text'   ] = hit['title'] + ' - ' + link['title']\n",
    "                s1['src'    ] = link['link'] if len(link['link']) > 0  else link['src']\n",
    "            else:\n",
    "                s1['text'   ] = hit[name   ][start:end]\n",
    "            \n",
    "            scores_dict['top_score_' + str(i+1)] = s1\n",
    "        \n",
    "        return scores_dict\n",
    "\n",
    "    res = {}\n",
    "    \n",
    "    res['source'] = source\n",
    "    res['title' ] = title\n",
    "    res['score' ] = f'{score:.2f}'\n",
    "    res['cutoff'] = False\n",
    "    res['url'   ] = url\n",
    "    \n",
    "    res['body'] = {}\n",
    "    res['body']['description'   ] = description\n",
    "    res['body']['identification'] = identification\n",
    "    res['body']['development'   ] = development\n",
    "    res['body']['damage'        ] = damage\n",
    "    res['body']['management'    ] = management\n",
    "\n",
    "    res['images'] = _format_images(links)\n",
    "    res['scores'] = _format_scores(hit)\n",
    "    \n",
    "    return res\n",
    "\n",
    "def _get_text(hits: dict) -> dict:\n",
    "    '''Process results for output.\n",
    "\n",
    "    Args:\n",
    "        hits (dict): Sorted results from ES query.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Data for chatbot to return.\n",
    "    '''\n",
    "\n",
    "    top_n = config.es_top_n\n",
    "    if len(hits) < config.es_top_n:\n",
    "        top_n = len(hits)\n",
    "\n",
    "    res = {\n",
    "        'text'      : 'Here are my top results:',\n",
    "        # 'payload'   : 'collapsible',\n",
    "        'payload'   : 'resultscollapsible',\n",
    "        'data'      : []\n",
    "    }\n",
    "\n",
    "    if len(hits):\n",
    "        for h in hits[:top_n]: res['data'].append(_format_result(h))   \n",
    "    \n",
    "    return res\n",
    "\n",
    "_get_text(hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def submit(\n",
    "    question    : str               ,\n",
    "    slots       : List[str] = None  ,\n",
    "    filter_ids  : List[str] = None\n",
    "\n",
    "    ) -> Tuple[dict, dict]:\n",
    "    \n",
    "    '''Perform ES query, transform results, print them, and return results.\n",
    "\n",
    "    Args:\n",
    "        question    (str)       : Question that is asked.\n",
    "        slots       (List[str]) : Pest damage description. Defaults to None.\n",
    "        filter_ids  (List[str]) : IDs of docs that should be considered. Defaults to None.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple[dict, dict]: Results from ES query. If slots were provided, then results with slots refinement.\n",
    "    '''\n",
    "\n",
    "    hits = await _handle_es_query(question, slots = slots, filter_ids = filter_ids)\n",
    "    \n",
    "    hits, filter_ids = _handle_es_result(hits)    \n",
    "    \n",
    "    res = _get_text(hits)\n",
    "    \n",
    "    return res, filter_ids\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question    = 'We have small caterpillars that have defoliated our small oak tree in one day. What are these and how can I get rid of them?'\n",
    "slots       = [\n",
    "    'defoliated small caterpillars small',\n",
    "    'oak tree caterpillars'\n",
    "]\n",
    "filter_ids = None\n",
    "\n",
    "hits, filter_ids = await submit(question, slots = slots, filter_ids = filter_ids)\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "362d59c0cf6dbeab3abcbfc8685ab4c27b49db463d853836c10c4cab9bbbe211"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('askchatbot-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

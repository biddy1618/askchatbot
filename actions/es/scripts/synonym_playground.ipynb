{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synonym transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main imports and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_SOURCE = './synonym_list/source/'\n",
    "FINAL_SOURCE = './synonym_list/transformed/'\n",
    "\n",
    "DATA_FILE_NAMES = sorted(os.listdir(PATH_SOURCE))\n",
    "DATA_FILE_NAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pest damages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = DATA_FILE_NAMES[0]\n",
    "df = pd.read_csv(PATH_SOURCE + FILE_NAME)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_synonyms'] = df['synonyms'].apply(lambda x: set([x1.strip().lower() for x1 in x.split(',')]) if not pd.isna(x) else set())\n",
    "df['set_synonyms'] = df.apply(lambda x: x['set_synonyms'].union(set([x['Pest damages']])).union(set([x['target name']])), axis = 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , df.shape[0]):\n",
    "        if len(df.iloc[i1]['set_synonyms'].intersection(df.iloc[i2]['set_synonyms'])) > 0:\n",
    "            print(f'Found intersection at lines {i1 + 2} and {i2 + 2}:')\n",
    "            print(f'{df.iloc[i1][\"Pest damages\"]} - {df.iloc[i1][\"set_synonyms\"]}')\n",
    "            print(f'{df.iloc[i2][\"Pest damages\"]} - {df.iloc[i2][\"set_synonyms\"]}')\n",
    "            print(f'Target - {df.iloc[i1][\"target name\"]} - {df.iloc[i2][\"target name\"]}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i, r in df.iterrows():\n",
    "    main_synonym = r['target name']\n",
    "    synonym_list = r['set_synonyms']\n",
    "    if main_synonym in synonym_dict:\n",
    "        synonym_dict[main_synonym] = synonym_dict[main_synonym].union(synonym_list)\n",
    "    else:\n",
    "        synonym_dict[main_synonym] = synonym_list\n",
    "\n",
    "damages_df = pd.DataFrame(data = {'main_synonym': synonym_dict.keys(), 'synonym_list': [', '.join(sorted(list(x))) for x in synonym_dict.values()]})\n",
    "damages_df = damages_df.sort_values('main_synonym')\n",
    "damages_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "damages_df.to_csv(FINAL_SOURCE + FILE_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pest names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = DATA_FILE_NAMES[1]\n",
    "df = pd.read_csv(PATH_SOURCE + FILE_NAME)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_synonyms'] = df['synonyms'].apply(lambda x: set([x1.strip().lower() for x1 in x.split(',')]) if not pd.isna(x) else set())\n",
    "df['set_synonyms'] = df.apply(lambda x: x['set_synonyms'].union(set([x['Pest names']])).union(set([x['target name']])), axis = 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , df.shape[0]):\n",
    "        if len(df.iloc[i1]['set_synonyms'].intersection(df.iloc[i2]['set_synonyms'])) > 0:\n",
    "            print(f'Found intersection at lines {i1 + 2} and {i2 + 2}:')\n",
    "            print(f'{df.iloc[i1][\"Pest names\"]} - {df.iloc[i1][\"set_synonyms\"]}')\n",
    "            print(f'{df.iloc[i2][\"Pest names\"]} - {df.iloc[i2][\"set_synonyms\"]}')\n",
    "            print(f'Target - {df.iloc[i1][\"target name\"]} - {df.iloc[i2][\"target name\"]}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i, r in df.iterrows():\n",
    "    main_synonym = r['target name']\n",
    "    synonym_list = r['set_synonyms']\n",
    "    if main_synonym in synonym_dict:\n",
    "        synonym_dict[main_synonym] = synonym_dict[main_synonym].union(synonym_list)\n",
    "    else:\n",
    "        synonym_dict[main_synonym] = synonym_list\n",
    "\n",
    "pests_df = pd.DataFrame(data = {'main_synonym': synonym_dict.keys(), 'synonym_list': [', '.join(sorted(list(x))) for x in synonym_dict.values()]})\n",
    "pests_df = pests_df.sort_values('main_synonym')\n",
    "pests_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pests_df.to_csv(FINAL_SOURCE + FILE_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = DATA_FILE_NAMES[2]\n",
    "df = pd.read_csv(PATH_SOURCE + FILE_NAME)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_synonyms'] = df['synonyms'].apply(lambda x: set([x1.strip().lower() for x1 in x.split(',')]) if not pd.isna(x) else set())\n",
    "df['set_synonyms'] = df.apply(lambda x: x['set_synonyms'].union(set([x['Plant names']])).union(set([x['target name']])), axis = 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , df.shape[0]):\n",
    "        if len(df.iloc[i1]['set_synonyms'].intersection(df.iloc[i2]['set_synonyms'])) > 0:\n",
    "            print(f'Found intersection at lines {i1 + 2} and {i2 + 2}:')\n",
    "            print(f'{df.iloc[i1][\"Plant names\"]} - {df.iloc[i1][\"set_synonyms\"]}')\n",
    "            print(f'{df.iloc[i2][\"Plant names\"]} - {df.iloc[i2][\"set_synonyms\"]}')\n",
    "            print(f'Intersection - {df.iloc[i1][\"set_synonyms\"].intersection(df.iloc[i2][\"set_synonyms\"])}')\n",
    "            print(f'Target - {df.iloc[i1][\"target name\"]} - {df.iloc[i2][\"target name\"]}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i, r in df.iterrows():\n",
    "    main_synonym = r['target name']\n",
    "    synonym_list = r['set_synonyms']\n",
    "    if main_synonym in synonym_dict:\n",
    "        synonym_dict[main_synonym] = synonym_dict[main_synonym].union(synonym_list)\n",
    "    else:\n",
    "        synonym_dict[main_synonym] = synonym_list\n",
    "\n",
    "plants_df = pd.DataFrame(data = {'main_synonym': synonym_dict.keys(), 'synonym_list': [', '.join(sorted(list(x))) for x in synonym_dict.values()]})\n",
    "plants_df = plants_df.sort_values('main_synonym')\n",
    "plants_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plants_df.to_csv(FINAL_SOURCE + FILE_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = DATA_FILE_NAMES[3]\n",
    "df = pd.read_csv(PATH_SOURCE + FILE_NAME)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_synonyms'] = df['synonyms'].apply(lambda x: set([x1.strip().lower() for x1 in x.split(',')]) if not pd.isna(x) else set())\n",
    "df['set_synonyms'] = df.apply(lambda x: x['set_synonyms'].union(set([x['Plant parts']])).union(set([x['target name']])), axis = 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , df.shape[0]):\n",
    "        if len(df.iloc[i1]['set_synonyms'].intersection(df.iloc[i2]['set_synonyms'])) > 0:\n",
    "            print(f'Found intersection at lines {i1 + 2} and {i2 + 2}:')\n",
    "            print(f'{df.iloc[i1][\"Plant parts\"]} - {df.iloc[i1][\"set_synonyms\"]}')\n",
    "            print(f'{df.iloc[i2][\"Plant parts\"]} - {df.iloc[i2][\"set_synonyms\"]}')\n",
    "            print(f'Intersection - {df.iloc[i1][\"set_synonyms\"].intersection(df.iloc[i2][\"set_synonyms\"])}')\n",
    "            print(f'Target - {df.iloc[i1][\"target name\"]} - {df.iloc[i2][\"target name\"]}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i, r in df.iterrows():\n",
    "    main_synonym = r['target name']\n",
    "    synonym_list = r['set_synonyms']\n",
    "    if main_synonym in synonym_dict:\n",
    "        synonym_dict[main_synonym] = synonym_dict[main_synonym].union(synonym_list)\n",
    "    else:\n",
    "        synonym_dict[main_synonym] = synonym_list\n",
    "\n",
    "parts_df = pd.DataFrame(data = {'main_synonym': synonym_dict.keys(), 'synonym_list': [', '.join(sorted(list(x))) for x in synonym_dict.values()]})\n",
    "parts_df = parts_df.sort_values('main_synonym')\n",
    "parts_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts_df.to_csv(FINAL_SOURCE + FILE_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plant types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = DATA_FILE_NAMES[4]\n",
    "df = pd.read_csv(PATH_SOURCE + FILE_NAME)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set_synonyms'] = df['synonyms'].apply(lambda x: set([x1.strip().lower() for x1 in x.split(',')]) if not pd.isna(x) else set())\n",
    "df['set_synonyms'] = df.apply(lambda x: x['set_synonyms'].union(set([x['Plant types']])).union(set([x['target name']])), axis = 1)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , df.shape[0]):\n",
    "        if len(df.iloc[i1]['set_synonyms'].intersection(df.iloc[i2]['set_synonyms'])) > 0:\n",
    "            print(f'Found intersection at lines {i1 + 2} and {i2 + 2}:')\n",
    "            print(f'{df.iloc[i1][\"Plant types\"]} - {df.iloc[i1][\"set_synonyms\"]}')\n",
    "            print(f'{df.iloc[i2][\"Plant types\"]} - {df.iloc[i2][\"set_synonyms\"]}')\n",
    "            print(f'Intersection - {df.iloc[i1][\"set_synonyms\"].intersection(df.iloc[i2][\"set_synonyms\"])}')\n",
    "            print(f'Target - {df.iloc[i1][\"target name\"]} - {df.iloc[i2][\"target name\"]}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synonym_dict = {}\n",
    "for i, r in df.iterrows():\n",
    "    main_synonym = r['target name']\n",
    "    synonym_list = r['set_synonyms']\n",
    "    if main_synonym in synonym_dict:\n",
    "        synonym_dict[main_synonym] = synonym_dict[main_synonym].union(synonym_list)\n",
    "    else:\n",
    "        synonym_dict[main_synonym] = synonym_list\n",
    "\n",
    "types_df = pd.DataFrame(data = {'main_synonym': synonym_dict.keys(), 'synonym_list': [', '.join(sorted(list(x))) for x in synonym_dict.values()]})\n",
    "types_df = types_df.sort_values('main_synonym')\n",
    "types_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "types_df.to_csv(FINAL_SOURCE + FILE_NAME, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving synonym dictionary to pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Shapes of DFs: damages - {damages_df.shape}, pests - {pests_df.shape}, plants - {plants_df.shape}, parts - {parts_df.shape}, types - {types_df.shape}')\n",
    "final_df = pd.concat([damages_df, pests_df, plants_df, parts_df, types_df], axis = 0)\n",
    "print(f'Final shape: {final_df.shape}')\n",
    "final_df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i1 in range(0, final_df.shape[0] - 1):\n",
    "    for i2 in range(i1 + 1 , final_df.shape[0]):\n",
    "        s1 = set(final_df.iloc[i1]['synonym_list'].split(', '))\n",
    "        s2 = set(final_df.iloc[i2]['synonym_list'].split(', '))\n",
    "        if len(s1.intersection(s2)) > 0:\n",
    "            print(f'Found intersection at rows {i1} and {i2}:')\n",
    "            print(f'{final_df.iloc[i1][\"main_synonym\"]} - {final_df.iloc[i1][\"synonym_list\"]}')\n",
    "            print(f'{final_df.iloc[i2][\"main_synonym\"]} - {final_df.iloc[i2][\"synonym_list\"]}')\n",
    "            print(f'Intersection - {s1.intersection(s2)}')\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Unique main synonyms: {final_df[\"main_synonym\"].nunique()}')\n",
    "\n",
    "n_synonyms = 0\n",
    "s_synonyms = set()\n",
    "for synonyms in final_df['synonym_list']:\n",
    "    s = set(synonyms.split(', '))\n",
    "    if len(s) + len(s_synonyms) != len(s_synonyms.union(s)):\n",
    "        print(f'Following secondary synonym(s) have duplicates - {\", \".join(s)}')\n",
    "    n_synonyms += len(s)\n",
    "    s_synonyms = s_synonyms.union(s)\n",
    "\n",
    "print(f'Number of secondary synonyms: {n_synonyms}')\n",
    "print(f'Number of unique secondary synonyms: {len(s_synonyms)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "synonym_dict_reverse = {}\n",
    "for i, r in final_df.iterrows():\n",
    "    synonym_list = r['synonym_list'].split(', ')\n",
    "    for s in synonym_list:\n",
    "        synonym_dict_reverse[s] = r['main_synonym']\n",
    "\n",
    "PICKLE_NAME = 'synonym_pest.pickle'\n",
    "with open(FINAL_SOURCE + PICKLE_NAME, 'wb') as handle:\n",
    "    pickle.dump(synonym_dict_reverse, handle, protocol = pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(FINAL_SOURCE + PICKLE_NAME, 'rb') as handle:\n",
    "    synonym_dict = pickle.load(handle)\n",
    "synonym_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    "The longest synonym is 5 words long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('askchatbot-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "362d59c0cf6dbeab3abcbfc8685ab4c27b49db463d853836c10c4cab9bbbe211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

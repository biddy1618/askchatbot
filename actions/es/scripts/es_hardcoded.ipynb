{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for hardcoded questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "os.environ['ES_USERNAME'    ] = 'elastic'\n",
    "os.environ['ES_PASSWORD'    ] = 'changeme'\n",
    "os.environ['ES_HOST'        ] = 'http://localhost:9200/'\n",
    "\n",
    "import config\n",
    "\n",
    "# set the es_search_size parameter in config to 2000 (can be more, but it is going to be slower)\n",
    "config.es_search_size = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./hardcoded/source/Questions with Issues July 2022 - transformed.csv', usecols = ['Group', 'Question', 'Answers'])\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby('Group').first().reset_index()\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dictionary of static results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to adjust the `search_size` if not all correct links were found (for time being it is set up to 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _cos_sim_query(query_vector: np.ndarray) -> dict:\n",
    "    '''Exectute vector search in ES based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        query_vector    (np.ndarray): Query vector.\n",
    "\n",
    "    Returns:\n",
    "        dict: Return hits.\n",
    "    '''\n",
    "    vector_name     = 'vectors.vector'\n",
    "    source_nested   = {'includes': ['vectors.name', 'vectors.start', 'vectors.end']}\n",
    "\n",
    "    cos     = f'cosineSimilarity(params.query_vector, \"{vector_name}\") + 1.0'\n",
    "    script  = {\"source\": cos, \"params\": {\"query_vector\": query_vector}}\n",
    "\n",
    "    source_query = {'includes': ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']}\n",
    "\n",
    "    path = vector_name.split('.')[0]\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\"nested\": {\n",
    "                        \"score_mode\": \"max\" ,\n",
    "                        \"path\"      : path  ,\n",
    "                        \"inner_hits\": {\"size\": 3, \"name\": \"nested\", \"_source\": source_nested},\n",
    "                        \"query\"     : {\"function_score\": {\"script_score\": {\"script\": script}}}}\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = await config.es_client.search(\n",
    "        index   = config.es_combined_index  ,\n",
    "        query   = query                     ,\n",
    "        size    = config.es_search_size     ,\n",
    "        _source = source_query\n",
    "    )\n",
    "\n",
    "    hits = []\n",
    "\n",
    "    for h1 in response['hits']['hits']:\n",
    "        top_scores = []\n",
    "\n",
    "        for h2 in h1['inner_hits']['nested']['hits']['hits']:\n",
    "            top_scores.append({'score': h2['_score'] - 1, 'source': h2['_source']})\n",
    "        \n",
    "        h1['_source']['top_scores'  ] = top_scores\n",
    "        h1['_source']['_id'         ] = h1['_id'    ]\n",
    "        h1['_source']['_score'      ] = h1['_score' ] - 1\n",
    "        \n",
    "        hits.append(h1['_source'])\n",
    "\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "es_logger = logging.getLogger('elasticsearch')\n",
    "es_logger.setLevel(logging.WARNING)\n",
    "\n",
    "group_results = {}\n",
    "\n",
    "for i, r in groups.iterrows():\n",
    "    question_result = {'hits': []}\n",
    "    group = r['Group']\n",
    "    question = r[\"Question\"]\n",
    "    links = r['Answers'].split('\\n')\n",
    "    \n",
    "    print(f'Question in group {group}: {question}')\n",
    "    query_vector = config.embed.encode([question], show_progress_bar = False)[0]\n",
    "    hits = await _cos_sim_query(query_vector = query_vector)\n",
    "    found = False\n",
    "    for i1, h in enumerate(hits):\n",
    "        if h['url'].split('?')[0] in links:\n",
    "            print(f'Found correct link at {i1+1} result item - {h[\"url\"].split(\"?\")[0]}')\n",
    "            question_result['hits'].append(h)\n",
    "            found = True\n",
    "    if not found:\n",
    "        print('No corresponding result')\n",
    "    print(f'Total number of correct links - {len(links)}\\n')\n",
    "    group_results[group] = question_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in group_results.items():\n",
    "    l_hits = len(v['hits'])\n",
    "    scores_fake = sorted(np.random.uniform(low=0.8, high=.95, size=(l_hits,)))[::-1]\n",
    "    for i, h in enumerate(v['hits']):\n",
    "        print(f'Before score: {h[\"_score\"]}, new score: {scores_fake[i]}')\n",
    "        h['_score'] = scores_fake[i]\n",
    "        for top_score in h['top_scores']:\n",
    "            top_score['score'] = scores_fake[i]\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "results = []\n",
    "for i, r in df.iterrows():\n",
    "    group = r['Group']\n",
    "    question_item = deepcopy(group_results[group])\n",
    "    question_item['group'] = group\n",
    "\n",
    "    question = r['Question']\n",
    "    question_item['question'] = question\n",
    "    \n",
    "    tokens = config.tokenizer(question)\n",
    "    question_modified = ''\n",
    "    for token in tokens:\n",
    "        if not token.is_stop:\n",
    "            question_modified += token.text_with_ws\n",
    "    question_item['question_stop_words'] = question_modified\n",
    "    print(f'Original question: {question}')\n",
    "    print(f'Removing stopwords: {question_modified}', end = '\\n\\n')\n",
    "    \n",
    "    vector = config.embed.encode([question_modified], show_progress_bar = False)[0].tolist()\n",
    "    question_item['vector'] = vector\n",
    "    print(f'Result vector type and len: {type(vector), len(vector)}')\n",
    "    results.append(question_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in enumerate(results):\n",
    "    print(f'Index: {i}')\n",
    "    print(f'Group: {r[\"group\"]}')\n",
    "    print(f'Question: {r[\"question\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the es_search_size parameter in config back to 100\n",
    "config.es_search_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving into pickle and loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "SAVE_PATH = './hardcoded/transformed/hardcoded.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH, 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH, 'rb') as handle:\n",
    "    hardcoded_queries = pickle.load(handle)\n",
    "hardcoded_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation details in the main function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to update the code in `es_playground.ipynb` as well as in `es.py` files accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _handle_es_query(\n",
    "    query       : str               ,\n",
    "    slots       : List[str] = None\n",
    "    ) -> Tuple[list, str]:\n",
    "    '''Perform search in ES base.\n",
    "\n",
    "    Args:\n",
    "        query       (str)       : Query statement.\n",
    "        slots       (List[str]) : Additional entity queries. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[list, str]: Results from ES query and final transformed query that was embedded.\n",
    "                            If slots were provided, then results with slots refinement.\n",
    "    '''\n",
    "\n",
    "    def _synonym_replace(text):\n",
    "        tokens = config.tokenizer(text)\n",
    "        text_modified = \"\"\n",
    "        for token in tokens:\n",
    "            t = token.text.lower()\n",
    "                \n",
    "            if t in config.synonym_dict:\n",
    "                text_modified += config.synonym_dict[t]\n",
    "                text_modified += token.whitespace_\n",
    "            else:\n",
    "                text_modified += token.text_with_ws\n",
    "\n",
    "        return text_modified\n",
    "\n",
    "    def _check_for_hardcoded_queries(text):\n",
    "        \n",
    "        tokens = config.tokenizer(text)\n",
    "        text_modified = \"\"\n",
    "\n",
    "        for token in tokens:\n",
    "            if not token.is_stop:\n",
    "                text_modified += token.text_with_ws\n",
    "            \n",
    "        query_vector = config.embed.encode([text_modified], show_progress_bar = False)[0]\n",
    "        best_score  = 0\n",
    "        best_result = None\n",
    "\n",
    "        # for h_query in config.hardcoded_queries:\n",
    "        for h_query in hardcoded_queries:\n",
    "            h_query_vector = h_query['vector']\n",
    "            score = cosine_similarity([query_vector, h_query_vector])[0, 1]\n",
    "            if score > best_score:\n",
    "                best_score  = score\n",
    "                best_result = h_query\n",
    "\n",
    "        if best_score < config.es_hardcoded_threshold:\n",
    "            return None\n",
    "\n",
    "        return best_result        \n",
    "\n",
    "    check_hardcoded = _check_for_hardcoded_queries(query)\n",
    "    query = _synonym_replace(query)\n",
    "    \n",
    "    if slots:\n",
    "        query = '. '.join([query] + [_synonym_replace(s) for s in slots])\n",
    "    # TF HUB model\n",
    "    # query_vector = config.embed([query]).numpy()[0]\n",
    "\n",
    "    # Sentence Encoder model\n",
    "    query_vector = config.embed.encode([query], show_progress_bar = False)[0]\n",
    "    \n",
    "    hits = await _cos_sim_query(query_vector = query_vector)\n",
    "    \n",
    "    if check_hardcoded:\n",
    "        urls = set([h['url'] for h in check_hardcoded['hits']])\n",
    "        hits = [h for h in hits if h['url'] not in urls and h['_score'] > config.es_cut_off_hardcoded]\n",
    "        hits = check_hardcoded['hits'] + hits\n",
    "\n",
    "    return hits, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What could be causing the holes in my kale plant leaves?'\n",
    "hits, query = await _handle_es_query(question)\n",
    "\n",
    "for h in hits:\n",
    "    print(f\"{h['url']:<30s}, top score: {h['_score']}, and scores: {h['top_scores']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('askchatbot-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "362d59c0cf6dbeab3abcbfc8685ab4c27b49db463d853836c10c4cab9bbbe211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

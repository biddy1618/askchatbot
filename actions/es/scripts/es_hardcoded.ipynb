{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script for hardcoded questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of libraries and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "\n",
    "os.environ['ES_USERNAME'    ] = 'elastic'\n",
    "os.environ['ES_PASSWORD'    ] = 'changeme'\n",
    "os.environ['ES_HOST'        ] = 'http://localhost:9200/'\n",
    "\n",
    "import config\n",
    "\n",
    "# set the es_search_size parameter in config to 2000 (can be more, but it is going to be slower)\n",
    "config.es_search_size = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def _cos_sim_query(query_vector: np.ndarray) -> dict:\n",
    "    '''Exectute vector search in ES based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        query_vector    (np.ndarray): Query vector.\n",
    "\n",
    "    Returns:\n",
    "        dict: Return hits.\n",
    "    '''\n",
    "    vector_name     = 'vectors.vector'\n",
    "    source_nested   = {'includes': ['vectors.name', 'vectors.start', 'vectors.end']}\n",
    "    \n",
    "    cos     = f'cosineSimilarity(params.query_vector, \"{vector_name}\") + 1.0'\n",
    "    script  = {\"source\": cos, \"params\": {\"query_vector\": query_vector}}\n",
    "    \n",
    "    source_query = {'includes': ['source', 'url', 'title', 'description', 'identification', 'development', 'damage', 'management', 'links']}\n",
    "    \n",
    "    path = vector_name.split('.')[0]\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": {\"nested\": {\n",
    "                        \"score_mode\": \"max\" ,\n",
    "                        \"path\"      : path  ,\n",
    "                        \"inner_hits\": {\"size\": 3, \"name\": \"nested\", \"_source\": source_nested},\n",
    "                        \"query\"     : {\"function_score\": {\"script_score\": {\"script\": script}}}}\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    response = await config.es_client.search(\n",
    "        index   = config.es_combined_index  ,\n",
    "        query   = query                     ,\n",
    "        size    = config.es_search_size     ,\n",
    "        _source = source_query\n",
    "    )\n",
    "\n",
    "    hits = []\n",
    "\n",
    "    for h1 in response['hits']['hits']:\n",
    "        top_scores = []\n",
    "\n",
    "        for h2 in h1['inner_hits']['nested']['hits']['hits']:\n",
    "            top_scores.append({'score': h2['_score'] - 1, 'source': h2['_source']})\n",
    "        \n",
    "        h1['_source']['top_scores'  ] = top_scores\n",
    "        h1['_source']['_id'         ] = h1['_id'    ]\n",
    "        h1['_source']['_score'      ] = h1['_score' ] - 1\n",
    "        \n",
    "        hits.append(h1['_source'])\n",
    "\n",
    "    return hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./hardcoded/source/Questions with Issues July 2022 - transformed.csv', usecols = ['Question', 'Answers'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building dictionary of static results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure to adjust the `search_size` if not all correct links were found (for time being it is set up to 2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "es_logger = logging.getLogger('elasticsearch')\n",
    "es_logger.setLevel(logging.WARNING)\n",
    "\n",
    "results = []\n",
    "\n",
    "for i, r in df.iterrows():\n",
    "    question_result = {'hits': []}\n",
    "    question = r[\"Question\"]\n",
    "    links = r['Answers'].split('\\n')\n",
    "    \n",
    "    question_result['question'] = question\n",
    "    print(f'Question at index {i}: {question}')\n",
    "    query_vector = config.embed.encode([question], show_progress_bar = False)[0]\n",
    "    hits = await _cos_sim_query(query_vector = query_vector)\n",
    "    found = False\n",
    "    for i1, h in enumerate(hits):\n",
    "        if h['url'].split('?')[0] in links:\n",
    "            print(f'Found correct link at {i1+1} result item - {h[\"url\"].split(\"?\")[0]}')\n",
    "            question_result['hits'].append(h)\n",
    "            found = True\n",
    "    if not found:\n",
    "        print('No corresponding result')\n",
    "    print(f'Total number of correct links - {len(links)}\\n')\n",
    "    results.append(question_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for res in results:\n",
    "    question = res['question']\n",
    "    tokens = config.tokenizer(question)\n",
    "    question_modified = \"\"\n",
    "\n",
    "    for token in tokens:\n",
    "        if not token.is_stop:\n",
    "            question_modified += token.text_with_ws\n",
    "\n",
    "    res['question_stop_words'] = question_modified\n",
    "    print(f'Original question: {question}')\n",
    "    print(f'Removing stopwords: {question_modified}', end = '\\n\\n')\n",
    "\n",
    "    vector = config.embed.encode([question_modified], show_progress_bar = False)[0].tolist()\n",
    "    res['vector'] = vector\n",
    "    print(f'Result vector type and len: {type(vector), len(vector)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "SAVE_PATH = './hardcoded/source/hardcoded.pickle'\n",
    "with open(SAVE_PATH, 'wb') as handle:\n",
    "    pickle.dump(results, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH, 'rb') as handle:\n",
    "    hardcoded_dict = pickle.load(handle)\n",
    "hardcoded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('askchatbot-dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "362d59c0cf6dbeab3abcbfc8685ab4c27b49db463d853836c10c4cab9bbbe211"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
